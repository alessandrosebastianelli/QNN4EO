{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "meaning-partnership",
   "metadata": {},
   "source": [
    "# QNN4EO: a quantum convolutional neural network for satellite data classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-garage",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "The dataset is loaded through the DatasetHandler class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DatasetHandler import DatasetHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-copyright",
   "metadata": {},
   "source": [
    "### 1. Initialize the dataset handler\n",
    "\n",
    "The dataset handler is initialized using the root path of the dataset. In this cases the root path is  *EuroSAT*, this folder contains a sub-folder for each class as printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_path = 'EuroSAT'\n",
    "datasetHandler = DatasetHandler(dataset_root_path)\n",
    "datasetHandler.print_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-faculty",
   "metadata": {},
   "source": [
    "### 2. Select the two classes for the binary classification\n",
    "In order to run the binary classification, the used should select two classes from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1 = int(input('Class 1 [0-9]: '))\n",
    "print('\\t\\t',datasetHandler.classes[class_1], '\\n')\n",
    "\n",
    "class_2 = int(input('Class 2 [0-9]: '))\n",
    "print('\\t\\t',datasetHandler.classes[class_2], '\\n')\n",
    "\n",
    "classes_name = []\n",
    "classes_name.append(datasetHandler.classes[class_1].split('/')[-1])\n",
    "classes_name.append(datasetHandler.classes[class_2].split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-sauce",
   "metadata": {},
   "source": [
    "### 3. Load paths and labels\n",
    "After the selection of the two classes, the Dataset Handler loads images paths and images labels for both the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path, imgs_label = datasetHandler.load_paths_labels(classes = [datasetHandler.classes[class_1], datasetHandler.classes[class_2]])\n",
    "\n",
    "print('Dataset images: ', len(imgs_path))\n",
    "print('Dataset labels: ', len(imgs_label))\n",
    "print('Dataset sample -> image path: ', imgs_path[0], ' image label', imgs_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-mentor",
   "metadata": {},
   "source": [
    "### 4. Trainining-Validation split\n",
    "The paths and labels are then divided randomly in training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, val_images, val_labels = datasetHandler.train_validation_split(imgs_path, imgs_label, split_factor = 0.2)\n",
    "print('Training images: ',  train_images.shape)\n",
    "print('Training labels: ',  train_labels.shape)\n",
    "print('Validatiom images: ',  val_images.shape)\n",
    "print('Validation labels: ',  val_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-spring",
   "metadata": {},
   "source": [
    "### 5. Display a sample of the dataset\n",
    "In order to visualize the images and lables of the two classes selected, the utility *plotDataset* can be used to plot a sample of the training/validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plotDataset\n",
    "plotDataset(train_images, train_labels, classes_name, columns = 5, rows = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-yahoo",
   "metadata": {},
   "source": [
    "## CNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_Classifier import CNN_Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-equilibrium",
   "metadata": {},
   "source": [
    "### 1. Initialize the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = plt.imread(train_images[0]).shape\n",
    "n_classes = train_labels.shape[1]\n",
    "\n",
    "cnn = CNN_Classifier(img_shape = img_shape, n_classes = n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-kansas",
   "metadata": {},
   "source": [
    "### 2. Train the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 20\n",
    "train_generator = datasetHandler.cnn_data_loader(train_images, train_labels, batch_size = batch_size, img_shape = img_shape, n_classes = n_classes)\n",
    "val_generator = datasetHandler.cnn_data_loader(val_images, val_labels, batch_size = batch_size, img_shape = img_shape, n_classes = n_classes)\n",
    "\n",
    "history = cnn.train_model(epochs, batch_size, train_generator, val_generator, len(train_images), len(val_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-family",
   "metadata": {},
   "source": [
    "####Â After training the CNN model, save it in the trained_models folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.model.save(os.path.join('trained_models', 'CNN-' + classes_name[0] + '-VS-' + classes_name[1] + '.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-suggestion",
   "metadata": {},
   "source": [
    "### 3. Test the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "cnn.model = load_model(os.path.join('trained_models', 'CNN-' + classes_name[0] + '-VS-' + classes_name[1] + '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_generator = datasetHandler.cnn_data_loader(val_images, val_labels, batch_size = len(val_images), img_shape = img_shape, n_classes = n_classes)\n",
    "accuracy, precision, recall, f1 = cnn.evaluate_model(val_data_generator, classes_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-excuse",
   "metadata": {},
   "source": [
    "## QNN4EO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QNN4EO import QNN4EO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-twins",
   "metadata": {},
   "source": [
    "### 1. Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn4eo = QNN4EO()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-interest",
   "metadata": {},
   "source": [
    "### 2. Traing the QNN4EO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-profession",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_shape = plt.imread(train_images[0]).shape\n",
    "n_classes = train_labels.shape[1]\n",
    "epochs = 20\n",
    "\n",
    "train_generator = datasetHandler.qcnn_data_loader(train_images, train_labels, batch_size = 1, img_shape = img_shape)\n",
    "history = qnn4eo.train_model(epochs, train_generator, len(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(qnn4eo.state_dict(), os.path.join('trained_models', 'QNN4EO-' + classes_name[0] + '-VS-' + classes_name[1] + '.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-nightmare",
   "metadata": {},
   "source": [
    "### 3. Test the QNN4EO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn4eo.load_state_dict(torch.load(os.path.join('trained_models', 'QNN4EO-' + classes_name[0] + '-VS-' + classes_name[1] + '.h5')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-refund",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data_gen = datasetHandler.qcnn_data_loader(val_images, val_labels, batch_size = 1, img_shape = img_shape)\n",
    "accuracy, precision, recall, f1 = qnn4eo.evaluate_model(val_data_gen, len(val_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-catholic",
   "metadata": {},
   "source": [
    "# Running all the binary classification tests\n",
    "### Keep Attention! This process can last a lot\n",
    "\n",
    "The next cells can be used to automatically run all the possible binary classification test.\n",
    "\n",
    "For this cases, since the EuroSAT dataset contains 10 classes, the script will run 45 binary classifications. Thi script is structured as follow\n",
    "- Loading datates\n",
    "- CNN training\n",
    "- CNN testing\n",
    "- QNN4EO training\n",
    "- QNN4EO testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from CNN_Classifier import CNN_Classifier\n",
    "from DatasetHandler import DatasetHandler\n",
    "from QNN4EO import QNN4EO\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetHandler = DatasetHandler('EuroSAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-execution",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 1\n",
    "\n",
    "cnn_results = np.zeros((10, 10, 4))\n",
    "qnn4eo_results = np.zeros((10, 10, 4))\n",
    "classes_name = []\n",
    "\n",
    "for i in range(10):\n",
    "    class_1 = i\n",
    "    classes_name.append(datasetHandler.classes[class_1].split('/')[-1])\n",
    "    for j in range(10):\n",
    "        if i!=j and j>i:\n",
    "            class_2 = j\n",
    "\n",
    "            print(\"\\033[1m\" + 'Load dataset:' + \"\\033[0m\")\n",
    "            print(datasetHandler.classes[class_1])\n",
    "            print(datasetHandler.classes[class_2])\n",
    "\n",
    "            cs = []\n",
    "            cs.append(datasetHandler.classes[class_1].split('/')[-1])\n",
    "            cs.append(datasetHandler.classes[class_2].split('/')[-1])\n",
    "\n",
    "            imgs_path, imgs_label = datasetHandler.load_paths_labels(classes = [datasetHandler.classes[class_1], datasetHandler.classes[class_2]])\n",
    "            train_images, train_labels, val_images, val_labels = datasetHandler.train_validation_split(imgs_path, imgs_label, split_factor = 0.2)\n",
    "\n",
    "            img_shape = plt.imread(train_images[0]).shape\n",
    "            n_classes = train_labels.shape[1]\n",
    "\n",
    "            print(\"\\033[1m\" + 'Train CNN:' + \"\\033[0m\")\n",
    "            cnn = CNN_Classifier(img_shape = img_shape, n_classes = n_classes)\n",
    "            train_generator = datasetHandler.cnn_data_loader(train_images, train_labels, batch_size = batch_size, img_shape = img_shape, n_classes = n_classes)\n",
    "            val_generator = datasetHandler.cnn_data_loader(val_images, val_labels, batch_size = batch_size, img_shape = img_shape, n_classes = n_classes)\n",
    "            history = cnn.train_model(epochs, batch_size, train_generator, val_generator, len(train_images), len(val_images))\n",
    "\n",
    "            print(\"\\033[1m\" + 'Test CNN:' + \"\\033[0m\")\n",
    "            val_data_generator = datasetHandler.cnn_data_loader(val_images, val_labels, batch_size = len(val_images), img_shape = img_shape, n_classes = n_classes)\n",
    "            cnn_results[i,j,...] = cnn.evaluate_model(val_data_generator, cs)\n",
    "            \n",
    "            cnn.model.save(os.path.join('trained_models', 'CNN-' + cs[0] + '-VS-' + cs[1] + '.h5'))\n",
    "\n",
    "            print(\"\\033[1m\" + 'Train QNN4EO:' + \"\\033[0m\")\n",
    "            qnn4eo = QNN4EO()\n",
    "            img_shape = plt.imread(train_images[0]).shape\n",
    "            train_generator = datasetHandler.qcnn_data_loader(train_images, train_labels, batch_size = batch_size, img_shape = img_shape)\n",
    "            loss_list = qnn4eo.train_model(epochs, train_generator, len(train_images))\n",
    "\n",
    "            print(\"\\033[1m\" + 'Test QNN4EO:' + \"\\033[0m\")\n",
    "            val_data_gen = datasetHandler.qcnn_data_loader(val_images, val_labels, batch_size = batch_size, img_shape = img_shape)\n",
    "            qnn4eo_results[i,j,...] = qnn4eo.evaluate_model(val_data_gen, len(val_images))\n",
    "\n",
    "            torch.save(qnn4eo.state_dict(), os.path.join('trained_models', 'QNN4EO-' + cs[0] + '-VS-' + cs[1] + '.h5'))\n",
    "\n",
    "        elif i==j:\n",
    "            cnn_results[i,j] = np.nan\n",
    "            qnn4eo_results[i,j] = np.nan\n",
    "            \n",
    "# Fill the lower triangular matrix with the upper triangluar one\n",
    "cnn_results[...,0] = cnn_results[...,0] + cnn_results[...,0].T\n",
    "cnn_results[...,1] = cnn_results[...,1] + cnn_results[...,1].T\n",
    "cnn_results[...,2] = cnn_results[...,2] + cnn_results[...,2].T\n",
    "cnn_results[...,3] = cnn_results[...,3] + cnn_results[...,3].T\n",
    "\n",
    "qnn4eo_results[...,0] = qnn4eo_results[...,0] + qnn4eo_results[...,0].T\n",
    "qnn4eo_results[...,1] = qnn4eo_results[...,1] + qnn4eo_results[...,1].T\n",
    "qnn4eo_results[...,2] = qnn4eo_results[...,2] + qnn4eo_results[...,2].T\n",
    "qnn4eo_results[...,3] = qnn4eo_results[...,3] + qnn4eo_results[...,3].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-barbados",
   "metadata": {},
   "source": [
    "The next cell displays the confusion matricies for Accuracy, Precision, Recall and F1 scores, both for the CNN and the QNN4EO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = LinearSegmentedColormap.from_list(\n",
    "    name='red-green', \n",
    "    colors=['red','green']\n",
    ")\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (30, 10))\n",
    "\n",
    "sns.heatmap(cnn_results[...,0], linewidth=0.5, fmt='.1f', square = True, cmap = cmap, \n",
    "            annot = True, xticklabels = classes_name, yticklabels = classes_name, ax = axes[0]).set(title='CNN (Accuracy)')\n",
    "sns.heatmap(qnn4eo_results[...,0], linewidth=0.5, fmt='.1f', square = True, cmap = cmap, \n",
    "            annot = True, xticklabels = classes_name, yticklabels = classes_name, ax = axes[1]).set(title='QNN4EO (Accuracy)')\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (30, 10))\n",
    "sns.heatmap(cnn_results[...,1], linewidth=0.5, fmt='.1f', square = True, cmap = cmap, \n",
    "            annot = True, xticklabels = classes_name, yticklabels = classes_name, ax = axes[0]).set(title='CNN (Precision)')\n",
    "sns.heatmap(qnn4eo_results[...,1], linewidth=0.5, fmt='.1f', square = True, cmap = cmap, \n",
    "            annot = True, xticklabels = classes_name, yticklabels = classes_name, ax = axes[1]).set(title='QNN4EO (Precision)')\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (30, 10))\n",
    "sns.heatmap(cnn_results[...,2], linewidth=0.5, fmt='.1f', square = True, cmap = cmap, \n",
    "            annot = True, xticklabels = classes_name, yticklabels = classes_name, ax = axes[0]).set(title='CNN (Recall)')\n",
    "sns.heatmap(qnn4eo_results[...,2], linewidth=0.5, fmt='.1f',  square = True, cmap = cmap, \n",
    "            annot = True, xticklabels = classes_name, yticklabels = classes_name, ax = axes[1]).set(title='QNN4EO (Recall)')\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (30, 10))\n",
    "sns.heatmap(cnn_results[...,3], linewidth=0.5, fmt='.1f', square = True, cmap = cmap, \n",
    "            annot = True, xticklabels = classes_name, yticklabels = classes_name, ax = axes[0]).set(title='CNN (F1)')\n",
    "sns.heatmap(qnn4eo_results[...,3], linewidth=0.5, fmt='.1f', square = True, cmap = cmap, \n",
    "            annot = True, xticklabels = classes_name, yticklabels = classes_name, ax = axes[1]).set(title='QNN4EO (F1)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mean_accuracy = np.triu(cnn_results[...,0], k=1)\n",
    "qnn4eo_mean_accuracy = np.triu(qnn4eo_results[...,0], k=1)\n",
    "\n",
    "print('CNN overall accuracy: ',  cnn_mean_accuracy[cnn_mean_accuracy>0].mean())\n",
    "print('QNN4EO overall accuracy: ',  qnn4eo_mean_accuracy[qnn4eo_mean_accuracy>0].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-schedule",
   "metadata": {},
   "source": [
    "# Paper Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_results import import_results\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from CNN_Classifier import CNN_Classifier\n",
    "from QNN4EO import QNN4EO\n",
    "\n",
    "\n",
    "paper_cnn_results, paper_qnn4eo_results, paper_classes_name = import_results()\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "    name='red-green', \n",
    "    colors=['red','green']\n",
    ")\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (30, 11))\n",
    "sns.heatmap(paper_cnn_results, linewidth=0.5, fmt='.1f', square = True, cmap = cmap, \n",
    "            annot = True, xticklabels = paper_classes_name, yticklabels = paper_classes_name, ax = axes[0]).set(title='CNN (Accuracy)')\n",
    "sns.heatmap(paper_qnn4eo_results, linewidth=0.5, fmt='.1f', square = True, cmap = cmap, \n",
    "            annot = True, xticklabels = paper_classes_name, yticklabels = paper_classes_name, ax = axes[1]).set(title='QNN4EO (Accuracy)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mean_accuracy = np.triu(paper_cnn_results, k=1)\n",
    "qnn4eo_mean_accuracy = np.triu(paper_qnn4eo_results, k=1)\n",
    "\n",
    "\n",
    "print('CNN overall accuracy: ',  cnn_mean_accuracy[cnn_mean_accuracy>0].mean())\n",
    "print('QNN4EO overall accuracy: ',  qnn4eo_mean_accuracy[qnn4eo_mean_accuracy>0].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-pilot",
   "metadata": {},
   "source": [
    "## Test both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-license",
   "metadata": {},
   "source": [
    "Load CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_Classifier import CNN_Classifier\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "img_shape = plt.imread(train_images[0]).shape\n",
    "n_classes = train_labels.shape[1]\n",
    "cnn = CNN_Classifier(img_shape = img_shape, n_classes = n_classes)\n",
    "\n",
    "cnn.model = load_model(os.path.join('trained_models', 'CNN-' + classes_name[0] + '-VS-' + classes_name[1] + '.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-delay",
   "metadata": {},
   "source": [
    "Load QNN4EO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QNN4EO import QNN4EO\n",
    "import torch\n",
    "\n",
    "qnn4eo = QNN4EO()\n",
    "\n",
    "qnn4eo.load_state_dict(torch.load(os.path.join('trained_models', 'QNN4EO-' + classes_name[0] + '-VS-' + classes_name[1] + '.h5')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-aggregate",
   "metadata": {},
   "source": [
    "Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-meeting",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qnn4eo.eval()\n",
    "\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows = nrows, ncols = ncols, figsize = (15, 10))\n",
    "\n",
    "for x in range(nrows):\n",
    "    for y in range(ncols):\n",
    "        \n",
    "        cnt = np.random.randint(0, high = len(val_images)-1, size=[1])[0]\n",
    "        \n",
    "        ground_truth = val_labels[cnt]\n",
    "        \n",
    "        img = plt.imread(val_images[cnt])/255.0\n",
    "        \n",
    "        cnn_input = np.zeros((1, 64, 64, 3))\n",
    "        cnn_input[0, ...] = img\n",
    "        \n",
    "        cnn_pred = cnn.model.predict(cnn_input)\n",
    "        \n",
    "        qnn4eo_input = np.zeros((1, 3, 64, 64))\n",
    "        qnn4eo_input[0, ...] = np.transpose(img)\n",
    "        with torch.no_grad():\n",
    "            qnn4eo_pred = qnn4eo(torch.Tensor(qnn4eo_input))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(ground_truth, cnn_pred, qnn4eo_pred)\n",
    "        axes[x,y].imshow(img)\n",
    "        axes[x,y].set_title(\"Class \" + str(classes_name[np.argmax(ground_truth)]) +\": \" +str(ground_truth)  + \"\\n\" + \n",
    "                            \"CNN Prediction: [%.2f, %.2f] \\n QNN4EO Prediction: [%.2f, %.2f]\" % (cnn_pred[0][0], cnn_pred[0][1], qnn4eo_pred[0].tolist()[0], qnn4eo_pred[0].tolist()[1]))\n",
    "        \n",
    "        axes[x,y].axis(False)\n",
    "\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
